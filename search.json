[
  {
    "objectID": "posts/future_map.html",
    "href": "posts/future_map.html",
    "title": "Future Map",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "Blog",
      "Posts",
      "Future Map"
    ]
  },
  {
    "objectID": "posts/03_Time_Series_Analysis.html",
    "href": "posts/03_Time_Series_Analysis.html",
    "title": "Building, testing and Deploying Time-Series ML models",
    "section": "",
    "text": "https://bthek1.github.io/TimeSeriesML/\n\nDeveloped during my exploration of Time Series Machine Learning methodologies for my internship, this Time Series technique operates similarly to traditional ML models. However, due to the temporal nature of the data, many techniques require adjustments and sequential training to effectively capture patterns and make accurate predictions.\nIn time series ML, models need to be trained and evaluated differently. For instance, instead of randomly splitting data into training and testing sets, chronological ordering is crucial, with earlier data used for training and later data for testing. Additionally, techniques like feature engineering may involve creating lag features or rolling statistics to capture temporal patterns.\nOverall, the primary difference lies in how time series ML methods handle the time-dependent nature of the data, requiring specialized techniques tailored to sequential data analysis.\n\n\n\n\n\nAutoARIMA\nHoltWinters\nCrostonClassic\nHistoricAverage\nDynamicOptimizedTheta as DOT\nSeasonalNaive\nMSTL\n\n\n\n\n\nXGBRegressor\nLGBMRegressor\nLinearRegression\n\n\n\n\n\nNBEATS\nNHITS\nMLP\nRNN\nLSTM\n\n\n\n\n\nNixtla\nDarts\nXGBoost\nProphet",
    "crumbs": [
      "Blog",
      "Posts",
      "Building, testing and Deploying Time-Series ML models"
    ]
  },
  {
    "objectID": "posts/03_Time_Series_Analysis.html#time-series-analysis",
    "href": "posts/03_Time_Series_Analysis.html#time-series-analysis",
    "title": "Building, testing and Deploying Time-Series ML models",
    "section": "",
    "text": "https://bthek1.github.io/TimeSeriesML/\n\nDeveloped during my exploration of Time Series Machine Learning methodologies for my internship, this Time Series technique operates similarly to traditional ML models. However, due to the temporal nature of the data, many techniques require adjustments and sequential training to effectively capture patterns and make accurate predictions.\nIn time series ML, models need to be trained and evaluated differently. For instance, instead of randomly splitting data into training and testing sets, chronological ordering is crucial, with earlier data used for training and later data for testing. Additionally, techniques like feature engineering may involve creating lag features or rolling statistics to capture temporal patterns.\nOverall, the primary difference lies in how time series ML methods handle the time-dependent nature of the data, requiring specialized techniques tailored to sequential data analysis.\n\n\n\n\n\nAutoARIMA\nHoltWinters\nCrostonClassic\nHistoricAverage\nDynamicOptimizedTheta as DOT\nSeasonalNaive\nMSTL\n\n\n\n\n\nXGBRegressor\nLGBMRegressor\nLinearRegression\n\n\n\n\n\nNBEATS\nNHITS\nMLP\nRNN\nLSTM\n\n\n\n\n\nNixtla\nDarts\nXGBoost\nProphet",
    "crumbs": [
      "Blog",
      "Posts",
      "Building, testing and Deploying Time-Series ML models"
    ]
  },
  {
    "objectID": "posts/creating_pypi_library.html",
    "href": "posts/creating_pypi_library.html",
    "title": "Creating Pypi Library",
    "section": "",
    "text": "https://bthek1.github.io/nbdevAuto/functions.html\n\nThis automation library was created for the perpose of speed up common daily task.\nLike for example, after pip install nbdevAuto. The cli command upload will automatically:\n\nnbdev_clean\nnbdev_export\ngit add .\ngit push.\n\n\n!pip list | grep nbdevAuto\n\nnbdevAuto                           0.0.112     /home/ben/BENEDICT_Only/Benedict_Projects/Benedict_ML/nbdevAuto\n\n\n\n\n\n!h\n\ncreate_cfast              create mamba env cfast\neverything                prep, gacp, release, reinstall\ngacp                      git add, commit and push to github\ngitrelease                release to git\nh                         Show help for all console scripts\npiprelease                release to pypi\nprep                      Export, test, and clean notebooks, and render README if needed\nreinstall                 runs pip install -e .\nrelease                   release to github and pip\nupdate                    prep, then reinstall\nupload                    prep, then gacp\n\n\nAlso, the library contains function to simplify download images for the internet for image classification deep learning like:\n\nfrom nbdevAuto.functions import *\n\n\ndownload_pic?\n\n\nSignature:\ndownload_pic(\n    image: str,\n    n_images: int = 1,\n    name: str = '',\n    folder: str = '',\n    show_progress: bool = False,\n    recreate: bool = False,\n)\nDocstring: Downloads the image into the folder provided and displays it\nFile:      ~/BENEDICT_Only/Benedict_Projects/Benedict_ML/nbdevAuto/nbdevAuto/functions.py\nType:      function\n\n\n\n\ndownload_pic('bird',\n             n_images = 1,\n             folder = './Data',\n             show_progress=False,\n             recreate = True)\n\n\n\n\n\n\n\n\n\n\n\n\ncreate_data_folder?\n\n\nSignature:\ncreate_data_folder(\n    folder_path: str,\n    searches: tuple,\n    before: str = '',\n    after: str = '',\n    amount: int = 200,\n    recreate: bool = False,\n    show_progress: bool = False,\n)\nDocstring: generate image data\nFile:      ~/BENEDICT_Only/Benedict_Projects/Benedict_ML/nbdevAuto/nbdevAuto/functions.py\nType:      function",
    "crumbs": [
      "Blog",
      "Posts",
      "Creating Pypi Library"
    ]
  },
  {
    "objectID": "posts/creating_pypi_library.html#nbdevauto",
    "href": "posts/creating_pypi_library.html#nbdevauto",
    "title": "Creating Pypi Library",
    "section": "",
    "text": "https://bthek1.github.io/nbdevAuto/functions.html\n\nThis automation library was created for the perpose of speed up common daily task.\nLike for example, after pip install nbdevAuto. The cli command upload will automatically:\n\nnbdev_clean\nnbdev_export\ngit add .\ngit push.\n\n\n!pip list | grep nbdevAuto\n\nnbdevAuto                           0.0.112     /home/ben/BENEDICT_Only/Benedict_Projects/Benedict_ML/nbdevAuto\n\n\n\n\n\n!h\n\ncreate_cfast              create mamba env cfast\neverything                prep, gacp, release, reinstall\ngacp                      git add, commit and push to github\ngitrelease                release to git\nh                         Show help for all console scripts\npiprelease                release to pypi\nprep                      Export, test, and clean notebooks, and render README if needed\nreinstall                 runs pip install -e .\nrelease                   release to github and pip\nupdate                    prep, then reinstall\nupload                    prep, then gacp\n\n\nAlso, the library contains function to simplify download images for the internet for image classification deep learning like:\n\nfrom nbdevAuto.functions import *\n\n\ndownload_pic?\n\n\nSignature:\ndownload_pic(\n    image: str,\n    n_images: int = 1,\n    name: str = '',\n    folder: str = '',\n    show_progress: bool = False,\n    recreate: bool = False,\n)\nDocstring: Downloads the image into the folder provided and displays it\nFile:      ~/BENEDICT_Only/Benedict_Projects/Benedict_ML/nbdevAuto/nbdevAuto/functions.py\nType:      function\n\n\n\n\ndownload_pic('bird',\n             n_images = 1,\n             folder = './Data',\n             show_progress=False,\n             recreate = True)\n\n\n\n\n\n\n\n\n\n\n\n\ncreate_data_folder?\n\n\nSignature:\ncreate_data_folder(\n    folder_path: str,\n    searches: tuple,\n    before: str = '',\n    after: str = '',\n    amount: int = 200,\n    recreate: bool = False,\n    show_progress: bool = False,\n)\nDocstring: generate image data\nFile:      ~/BENEDICT_Only/Benedict_Projects/Benedict_ML/nbdevAuto/nbdevAuto/functions.py\nType:      function",
    "crumbs": [
      "Blog",
      "Posts",
      "Creating Pypi Library"
    ]
  },
  {
    "objectID": "posts/creating_pypi_library.html#for-downloading-kaggle-files",
    "href": "posts/creating_pypi_library.html#for-downloading-kaggle-files",
    "title": "Creating Pypi Library",
    "section": "For downloading kaggle files",
    "text": "For downloading kaggle files\n\nkaggle_competition_download??\n\n\nSignature: kaggle_competition_download(name: str, folderpath: str = './Data')\nSource:   \ndef kaggle_competition_download(name:str, folderpath:str = './Data'):\n    'download competition files from kaggle'\n    import os\n    import shutil\n    from pathlib import Path\n    \n    iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n    if iskaggle: path = Path(f'../input/{name}')\n    else:\n        path = Path(f'{folderpath}/{name}')\n        if path.exists():print(\"file exists\")\n        else:\n            import zipfile,kaggle\n            kaggle.api.competition_download_cli(competition = name, path = path)\n            zipfile.ZipFile(f'{path}/{name}.zip').extractall(path)\nFile:      ~/BENEDICT_Only/Benedict_Projects/Benedict_ML/nbdevAuto/nbdevAuto/functions.py\nType:      function",
    "crumbs": [
      "Blog",
      "Posts",
      "Creating Pypi Library"
    ]
  },
  {
    "objectID": "posts/future_plan.html",
    "href": "posts/future_plan.html",
    "title": "Future Plan",
    "section": "",
    "text": "Laser\nPhisaver\nRecovery Metrics\nDrone ecommerce\nUni Jupyter labs",
    "crumbs": [
      "Blog",
      "Posts",
      "Future Plan"
    ]
  },
  {
    "objectID": "posts/future_plan.html#income",
    "href": "posts/future_plan.html#income",
    "title": "Future Plan",
    "section": "",
    "text": "Laser\nPhisaver\nRecovery Metrics\nDrone ecommerce\nUni Jupyter labs",
    "crumbs": [
      "Blog",
      "Posts",
      "Future Plan"
    ]
  },
  {
    "objectID": "posts/future_plan.html#goals",
    "href": "posts/future_plan.html#goals",
    "title": "Future Plan",
    "section": "Goals",
    "text": "Goals\n\nML research - ForResNet\n3D App\nBackend- RM\nFrontend - Phisaver, RM\nAppdevelopment - Phisaver\nMarketing - Phisaver",
    "crumbs": [
      "Blog",
      "Posts",
      "Future Plan"
    ]
  },
  {
    "objectID": "posts/future_plan.html#ideas",
    "href": "posts/future_plan.html#ideas",
    "title": "Future Plan",
    "section": "Ideas",
    "text": "Ideas\n\nspinning light\nForResnet\nrandom forward and backward\nDigikey Dropshipping",
    "crumbs": [
      "Blog",
      "Posts",
      "Future Plan"
    ]
  },
  {
    "objectID": "posts/future_plan.html#breakdown",
    "href": "posts/future_plan.html#breakdown",
    "title": "Future Plan",
    "section": "Breakdown",
    "text": "Breakdown\n\nLaser\n\nshipstation\nphotoshop\ndesigns\n\n\n\nFASTAI, CSSEML, MATLAB\n\n\nDrone - Drop shipping\n\n\nWebdevelopment\n\noracle\ndjango\nreact\n\n\n\nApp development\n\nflutter\n3D vision",
    "crumbs": [
      "Blog",
      "Posts",
      "Future Plan"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Benedicts Blog",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nExploring Deeplearning\n\n\nI’ve been immersing myself in PyTorch and fastAI for some time. Everything I’ve absorbed can be categorized into three main areas: FastAI setup, the FastAI course, and deep learning.\n\n\n\n\n\nApr 26, 2024\n\n\nBenedict Thekkel\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Machine Learning\n\n\nI’ve developed two libraries to delve into machine learning techniques. The ML repo delves into various methods, while MLtools provide in-depth exploration of commonly used libraries that assist in ML development, such as matplotlib, numpy, pandas, scipy, and more.\n\n\n\n\n\nApr 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding, testing and Deploying Time-Series ML models\n\n\nDuring my internship, I was tasked with developing models to forecast electricity usage for an electricity monitoring company.\n\n\n\n\n\nApr 24, 2024\n\n\nBenedict Thekkel\n\n\n\n\n\n\n\n\n\n\n\n\nAdventure into Web and App development\n\n\nI came to the realization that knowledge of AI along isn’t that useful unless you can deploy it the public. Hence my interest into web development.\n\n\n\n\n\nApr 23, 2024\n\n\nBenedict Thekkel\n\n\n\n\n\n\n\n\n\n\n\n\nCreating Pypi Library\n\n\nI’ve been utilizing nbdev to generate webpages from GitHub repositories. However, nbdev’s main function is to produce Python libraries for distribution via conda and pip. I’ve developed a Python library named NbdevAuto for this purpose.\n\n\n\n\n\nApr 22, 2024\n\n\nBenedict Thekkel\n\n\n\n\n\n\n\n\n\n\n\n\nFuture Plan\n\n\nBreakdown of future learning goals\n\n\n\n\n\nApr 21, 2024\n\n\nBenedict Thekkel\n\n\n\n\n\n\n\n\n\n\n\n\nFuture Map\n\n\nFuture Map\n\n\n\n\n\nApr 20, 2024\n\n\nBenedict Thekkel\n\n\n\n\n\nNo matching items\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Blog",
      "Benedicts Blog"
    ]
  },
  {
    "objectID": "posts/web_development.html",
    "href": "posts/web_development.html",
    "title": "Adventure into Web and App development",
    "section": "",
    "text": "https://bthek1.github.io/webdevelopment_doc/\n\nWeb Developement contains information many of servers application I have used untill now aswell as database and front-end applications. There include:\n\n\n\nInflux\nDjango\nNginx\nDocker\nPrefect\n\n\n\n\n\nStreamlit\nGradio\nFlutter\nReact\nReact-Naive",
    "crumbs": [
      "Blog",
      "Posts",
      "Adventure into Web and App development"
    ]
  },
  {
    "objectID": "posts/web_development.html#web-development",
    "href": "posts/web_development.html#web-development",
    "title": "Adventure into Web and App development",
    "section": "",
    "text": "https://bthek1.github.io/webdevelopment_doc/\n\nWeb Developement contains information many of servers application I have used untill now aswell as database and front-end applications. There include:\n\n\n\nInflux\nDjango\nNginx\nDocker\nPrefect\n\n\n\n\n\nStreamlit\nGradio\nFlutter\nReact\nReact-Naive",
    "crumbs": [
      "Blog",
      "Posts",
      "Adventure into Web and App development"
    ]
  },
  {
    "objectID": "posts/01_Exploring_Deeplearning.html",
    "href": "posts/01_Exploring_Deeplearning.html",
    "title": "Exploring Deeplearning",
    "section": "",
    "text": "https://bthek1.github.io/FastAISetup/\n\nThe repo FastAISetup contains a complete breakdown and setup process for your computer to be able to use for AI development\nInstruction on setting up:\n\nComputer WSL environment\nConda environment\nNbdev installation\nQuarto installation\nPytorch installation\nFastAI setup\nFastAI testing\nJuptyer guide for future reference\nLatex installation",
    "crumbs": [
      "Blog",
      "Posts",
      "Exploring Deeplearning"
    ]
  },
  {
    "objectID": "posts/01_Exploring_Deeplearning.html#fast-ai-setup",
    "href": "posts/01_Exploring_Deeplearning.html#fast-ai-setup",
    "title": "Exploring Deeplearning",
    "section": "",
    "text": "https://bthek1.github.io/FastAISetup/\n\nThe repo FastAISetup contains a complete breakdown and setup process for your computer to be able to use for AI development\nInstruction on setting up:\n\nComputer WSL environment\nConda environment\nNbdev installation\nQuarto installation\nPytorch installation\nFastAI setup\nFastAI testing\nJuptyer guide for future reference\nLatex installation",
    "crumbs": [
      "Blog",
      "Posts",
      "Exploring Deeplearning"
    ]
  },
  {
    "objectID": "posts/01_Exploring_Deeplearning.html#fast-ai-course",
    "href": "posts/01_Exploring_Deeplearning.html#fast-ai-course",
    "title": "Exploring Deeplearning",
    "section": "Fast AI course",
    "text": "Fast AI course\n\nhttps://bthek1.github.io/fastAIcourse/\n\nFast AI course, as its named is my recreation of FastAI course by Jeremy Howard. Theres are the notes I used to learn and experiement in the contents of the course.\nIncludes:\n\nExploring FastAI\nDeploying using Hugging Face\nDeveloping FastAI from scratch\nDeveloping Diffusion Models\nDeveloping Resnet Models",
    "crumbs": [
      "Blog",
      "Posts",
      "Exploring Deeplearning"
    ]
  },
  {
    "objectID": "posts/01_Exploring_Deeplearning.html#deep-learning-from-scratch",
    "href": "posts/01_Exploring_Deeplearning.html#deep-learning-from-scratch",
    "title": "Exploring Deeplearning",
    "section": "Deep Learning from Scratch",
    "text": "Deep Learning from Scratch\n\nhttps://bthek1.github.io/DeepLearning/\n\nDeep Learning is the repo dedicated to learning the low level coding of Deep Learning models. It will also dive deeper into Image classification, detection, and segmentation in the future.",
    "crumbs": [
      "Blog",
      "Posts",
      "Exploring Deeplearning"
    ]
  },
  {
    "objectID": "posts/02_Exploring_Machine_Learning.html",
    "href": "posts/02_Exploring_Machine_Learning.html",
    "title": "Exploring Machine Learning",
    "section": "",
    "text": "https://bthek1.github.io/ML/\n\nThe ML repo contains example code of most of the popular ML techniques. Created to be a useful quick reference quide for ML developement. Techniques ranging from:\n\nKNN\nDecision Tree\nLinear Regression\nLogistic Regression\nL1 and L2 Regularication\nEnsemble Methods\nNaive Bayes\nSupper Vector Regression (SVR)\nRandom Forest\nPrincipal Component Analysis (PCA)\nCNN",
    "crumbs": [
      "Blog",
      "Posts",
      "Exploring Machine Learning"
    ]
  },
  {
    "objectID": "posts/02_Exploring_Machine_Learning.html#machine-learning-techniques",
    "href": "posts/02_Exploring_Machine_Learning.html#machine-learning-techniques",
    "title": "Exploring Machine Learning",
    "section": "",
    "text": "https://bthek1.github.io/ML/\n\nThe ML repo contains example code of most of the popular ML techniques. Created to be a useful quick reference quide for ML developement. Techniques ranging from:\n\nKNN\nDecision Tree\nLinear Regression\nLogistic Regression\nL1 and L2 Regularication\nEnsemble Methods\nNaive Bayes\nSupper Vector Regression (SVR)\nRandom Forest\nPrincipal Component Analysis (PCA)\nCNN",
    "crumbs": [
      "Blog",
      "Posts",
      "Exploring Machine Learning"
    ]
  },
  {
    "objectID": "posts/02_Exploring_Machine_Learning.html#helpful-tools-and-libraries-for-ml",
    "href": "posts/02_Exploring_Machine_Learning.html#helpful-tools-and-libraries-for-ml",
    "title": "Exploring Machine Learning",
    "section": "Helpful tools and Libraries for ML",
    "text": "Helpful tools and Libraries for ML\n\nhttps://bthek1.github.io/MLtools/\n\nML tools repo contain the breakdown of often used python libraries in conjuction with ML development. Created as a quick reference when trying to remember particular functions. The libraries include:\n\nMatplotlib\nNumpy\nScipy\nPandas\nPivot Tables\nPytube\nMito\nAltair\nTqdm\nIpywidget\nTmux\nbreakdown of Python class and design structures",
    "crumbs": [
      "Blog",
      "Posts",
      "Exploring Machine Learning"
    ]
  }
]